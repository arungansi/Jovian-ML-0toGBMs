{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##### my-zero-to-gbm-proj-assign"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "#import plotly.express as px\r\n",
    "#train = pd.read_csv('../../../data/optiver-realized-volatility-prediction/train.csv')\r\n",
    "train = pd.read_csv('d:\\\\optiver-realized-volatility-prediction\\\\train.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import glob\r\n",
    "list_order_book_file_train = glob.glob('d:\\\\optiver-realized-volatility-prediction\\\\book_train.parquet/*')\r\n",
    "list_trade_book_file_train = glob.glob('d:\\\\optiver-realized-volatility-prediction\\\\trade_train.parquet/*')\r\n",
    "#list_order_book_file_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%who"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_order_book = pd.DataFrame()\r\n",
    "for file in list_order_book_file_train:\r\n",
    "     df_stock_book = pd.read_parquet(file)\r\n",
    "     df_stock_book['stock_id'] = file.split('=')[1]\r\n",
    "     df_order_book = pd.concat([df_order_book,df_stock_book])\r\n",
    "\r\n",
    "\r\n",
    "df_trade_book = pd.DataFrame()\r\n",
    "for file in list_trade_book_file_train:\r\n",
    "     df_stock_book = pd.read_parquet(file)\r\n",
    "     df_stock_book['stock_id'] = file.split('=')[1]\r\n",
    "     df_trade_book = pd.concat([df_trade_book,df_stock_book])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# with open('book_index.csv','w+') as f:\r\n",
    "#     for items in list(df_order_book_50.index):\r\n",
    "#         f.write('%s\\n' %items)\r\n",
    "#new_index\r\n",
    "# df_order_book_5.reset_index(inplace=True,drop=True)\r\n",
    "# df_trade_book_5.reset_index(inplace=True,drop=True)\r\n",
    "\r\n",
    "df_order_book.reset_index(inplace=True,drop=True)\r\n",
    "df_trade_book.reset_index(inplace=True,drop=True)\r\n",
    "\r\n",
    "#df_order_book_50.head(-1)\r\n",
    "#df_order_book_50[df_order_book_50.index != df_order_book_50['index']]\r\n",
    "#(72311913, 11)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_order_book['stock_id'] = df_order_book['stock_id'].astype('int8')\r\n",
    "df_trade_book['stock_id'] = df_trade_book['stock_id'].astype('int8')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_order_book['order_wap'] = ((((df_order_book['bid_price1'].values * df_order_book['bid_size1'].values + df_order_book['bid_price2'].values * \r\n",
    "    df_order_book['bid_size2'].values)/(df_order_book['bid_size1'].values + df_order_book['bid_size2'].values)) * (df_order_book['ask_size1'].values + \r\n",
    "    df_order_book['ask_size2'].values)) + (((df_order_book['ask_price1'].values * df_order_book['ask_size1'].values + df_order_book['ask_price2'].values * \r\n",
    "    df_order_book['ask_size2'].values)/(df_order_book['ask_size1'].values + df_order_book['ask_size2'].values)) * (df_order_book['bid_size1'].values + \r\n",
    "    df_order_book['bid_size2'].values)) / ((df_order_book['bid_size1'].values + df_order_book['bid_size2'].values) +  (df_order_book['ask_size1'].values + \r\n",
    "    df_order_book['ask_size2'].values))).astype('float32')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_index = pd.Index(np.arange(0,600), name=\"seconds_in_bucket\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def log_return(list_stock_prices):\r\n",
    "    return np.log(list_stock_prices).diff()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "def order_volatility(series_log_return):\r\n",
    "    return np.sqrt(np.sum(series_log_return**2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_trade_book['scc'] = (df_trade_book['size']/df_trade_book['order_count']).values.astype('float16')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reg = df_trade_book['price'].corr(df_trade_book['scc'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_order_trade_merged = pd.merge(\r\n",
    "    df_order_book[['time_id','stock_id','seconds_in_bucket','order_wap']],\r\n",
    "    df_trade_book[['time_id','stock_id','seconds_in_bucket','price','scc']],\r\n",
    "    how=\"outer\",\r\n",
    "    on=['time_id','stock_id','seconds_in_bucket'],\r\n",
    "    sort=True,\r\n",
    "    copy=False,\r\n",
    "    indicator=False,\r\n",
    "    validate='m:m'\r\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "del [df_order_book,df_trade_book]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grouped = df_order_trade_merged.groupby(['time_id','stock_id'])['seconds_in_bucket','order_wap','price','scc']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s1 = grouped.apply(lambda x : x.set_index('seconds_in_bucket').reindex(new_index))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "del grouped"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bf = s1.groupby(['time_id','stock_id'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s1.loc[s1.index.get_level_values(2)==0,['order_wap','price','scc']] = bf.first()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "del bf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = s1.loc(axis=0)[:,:,0][s1.loc(axis=0)[:,:,0]['price'].isna()][['price','scc']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def price_scc(col):\r\n",
    "    #return  s1.loc(axis=0)[:,col.name[1],0][col.index[0]].mean(),s1.loc(axis=0)[:,col.name[1],:][col.index[1]].mean()\r\n",
    "    #return s1.loc(axis=0)[:,col.name[1],0].groupby(level=[1,2])['price'].mean(), s1.loc(axis=0)[:,col.name[1],0].groupby(level=[1,2])['scc'].mean()\r\n",
    "    return s1.loc(axis=0)[:,col.name[1],0]['price'].mean(), np.asscalar(s1.loc(axis=0)[:,col.name[1],0]['scc'].mean(skipna=True,level=[1,2]).values)\r\n",
    "    #return col.name[1] , col.index[0]\r\n",
    "    #row.scc = s1.loc(axis=0)[:,row.index.get_level_values(1),0]['scc'].mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "b = a.transform(price_scc ,axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s1.at[b.index.values,['price','scc']] = b[['price','scc']].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s1.loc(axis=0)[:,:,0].isna().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s1['price'].describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s2 = s1.groupby(['time_id','stock_id']).pad()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s2.isna().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "del [a,b,s1,df_order_trade_merged,df_stock_book]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looping through each individual stocks, we can get the past realized volatility as prediction for each individual stocks."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearnex import patch_sklearn\r\n",
    "patch_sklearn()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import Normalizer\r\n",
    "#scaler = MinMaxScaler(feature_range=(-0.001,0.001))\r\n",
    "scaler =  Normalizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def scc_dev_fn(x):\r\n",
    "    return scaler.fit_transform(x.values.reshape(-1,1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def trade_volatility(trade_wap_prices):\r\n",
    "    return np.sqrt(np.sum(trade_wap_prices)/len(trade_wap_prices))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s2['sccc'] = s2.groupby(['time_id','stock_id'])['scc'].transform(lambda x : x - np.mean(x.values)).astype('float16')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s2[['price','sccc']].describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s2['price_c'] = s2['price'] + pow(reg,2) * s2['sccc']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s2['price_c'].describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.options.display.float_format = '{:,.16f}'.format"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%who"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\r\n",
    "def sizeof_fmt(num, suffix='B'):\r\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\r\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\r\n",
    "        if abs(num) < 1024.0:\r\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\r\n",
    "        num /= 1024.0\r\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\r\n",
    "\r\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\r\n",
    "                         key= lambda x: -x[1])[:10]:\r\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s2.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "del s2['scc']\r\n",
    "del s2['sccc']\r\n",
    "del s2['price']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s2['trade_wap'] = s2.groupby(['time_id','stock_id'])['price_c'].apply(lambda x: pow(x - x.mean(),2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import winsound\r\n",
    "winsound.Beep(2500,3000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s2['trade_wap'].describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s2['log_return'] = s2.groupby(['time_id','stock_id'])['order_wap'].apply(log_return)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s2['log_return'].isna().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%who"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "del [glob,list_order_book_file_train,list_trade_book_file_train,name,new_index,scaler,size,sizeof_fmt,price_scc,reg,]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_realized_vol_per_stock =  pd.DataFrame(s2[~s2['log_return'].isnull()]['log_return'].groupby(['time_id','stock_id']).agg(order_volatility))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock.apply(lambda x: x.index.get_level_values(1).astype(str) + \"-\" + x.index.get_level_values(0).astype(str))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_realized_vol_per_stock['trade_return'] = pd.DataFrame(s2['trade_wap'].groupby(['time_id','stock_id']).agg(trade_volatility))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "winsound.Beep(2500,1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_realized_vol_per_stock.isna().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "winsound.Beep(2500,3000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_realized_vol_per_stock.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\r\n",
    "train = train[['row_id','target']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_joined = train.merge(df_realized_vol_per_stock, on = ['row_id'], how = 'inner')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_joined.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_joined.isna().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "inputs = df_joined[['log_return', 'trade_return']]\r\n",
    "targets = df_joined['target']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "inputs.to_csv('inputs.csv')\r\n",
    "targets.to_csv('targets.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "inputs = pd.read_csv('inputs.csv',index_col=0)\r\n",
    "targets = pd.read_csv('targets.csv',index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "inputs.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 428932 entries, 0 to 428931\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   log_return    428932 non-null  float64\n",
      " 1   trade_return  428932 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 9.8 MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "targets.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 428932 entries, 0 to 428931\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   target  428932 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 6.5 MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearnex import patch_sklearn\r\n",
    "patch_sklearn()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn.metrics import r2_score\r\n",
    "# def rmspe(y_true, y_pred):\r\n",
    "#     return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))) * 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from sklearn.model_selection import ShuffleSplit, RepeatedKFold"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# ss = ShuffleSplit(n_splits = 5, test_size = 0.25, random_state=11111)\r\n",
    "ss = RepeatedKFold(n_splits=2, n_repeats=3, random_state=11111)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\r\n",
    "poly = PolynomialFeatures(3)\r\n",
    "poly_inputs = pd.DataFrame(poly.fit_transform(inputs)).astype('float32')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from lightgbm import LGBMRegressor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# explicitly require this experimental feature\r\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\r\n",
    "# now you can import normally from model_selection\r\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\r\n",
    "from sklearn.model_selection import HalvingGridSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import sklearn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "sklearn. __version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1.0'"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "tuple(targets)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('target',)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "def train_and_evaluate(X_train, train_targets, X_val, val_targets, **params):\r\n",
    "    model = modelc\r\n",
    "    model.fit(X_train, train_targets)#,early_stopping_rounds=5,eval_set=(X_val,val_targets))\r\n",
    "    pred_train = model.predict(X_train)\r\n",
    "    pred_val = model.predict(X_val)\r\n",
    "    train_R2 = round(r2_score(train_targets,pred_train ),3)\r\n",
    "    train_RMSPE = round(mean_squared_error(train_targets, pred_train,squared=False),3)\r\n",
    "    val_R2 = round(r2_score(val_targets, pred_val),3)\r\n",
    "    val_RMSPE = round(mean_squared_error(val_targets, pred_val,squared=False),3)\r\n",
    "\r\n",
    "    # train_rmse = rmse(model.predict(X_train), train_targets)\r\n",
    "    # val_rmse = rmse(model.predict(X_val), val_targets)\r\n",
    "    return model, train_R2, train_RMSPE, val_R2, val_RMSPE\r\n",
    "#n_jobs = -1 means that use all the available threads in that machine where the alogorithm is running "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# models = []\r\n",
    "# for train_idxs, val_idxs in ss.split(inputs):\r\n",
    "#     X_train, train_targets = inputs.iloc[train_idxs], targets.iloc[train_idxs]\r\n",
    "#     X_val, val_targets = inputs.iloc[val_idxs], targets.iloc[val_idxs]\r\n",
    "#     X_train = np.ascontiguousarray(X_train).reshape(-1,2)\r\n",
    "#     train_targets = np.ascontiguousarray(train_targets).reshape(-1,1)\r\n",
    "#     X_val = np.ascontiguousarray(X_val).reshape(-1,2)\r\n",
    "#     val_targets = np.ascontiguousarray(val_targets).reshape(-1,1)\r\n",
    "#     reg = LazyRegressor(ignore_warnings=False, random_state=11111, verbose=True)\r\n",
    "#     models, predictions = reg.fit(X_train, X_val, train_targets, val_targets)  # pass all sets\r\n",
    "#     print(models.head(100))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# models = []\r\n",
    "\r\n",
    "# for train_idxs, val_idxs in ss.split(inputs):\r\n",
    "#    X_train, train_targets = inputs.iloc[train_idxs], targets.iloc[train_idxs]\r\n",
    "#    X_val, val_targets = inputs.iloc[val_idxs], targets.iloc[val_idxs]\r\n",
    "#    X_train = np.ascontiguousarray(X_train).reshape(-1,2)\r\n",
    "#    train_targets = np.ascontiguousarray(train_targets).reshape(-1,1)\r\n",
    "#    X_val = np.ascontiguousarray(X_val).reshape(-1,2)\r\n",
    "#    val_targets = np.ascontiguousarray(val_targets).reshape(-1,1)\r\n",
    "#    model, train_R2, train_RMSPE, val_R2, val_RMSPE = train_and_evaluate(X_train, \r\n",
    "#                                                    train_targets, \r\n",
    "#                                                    X_val, \r\n",
    "#                                                    val_targets, \r\n",
    "#                                                    n_estimators=1000,\r\n",
    "#                                                    booster='gbtree',\r\n",
    "#                                                    verbosity=2)\r\n",
    "#    models.append(model)\r\n",
    "#    print('Train R2: {}, Train RMSPE: {}, Validation R2: {}, Validation RMSPE: {}'.format(train_R2, train_RMSPE, val_R2, val_RMSPE))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# model = XGBRegressor(random_state=11111, n_jobs=-1,verbosity=1,objective='reg:tweedie')\r\n",
    "# param_grid = {\"n_estimators\" : [50,100,500],\r\n",
    "#               \"learning_rate\": [0.1,0.01,0.001],\r\n",
    "#               \"booster\": ['gbtree', 'gblinear'],\r\n",
    "#               # \"num_parallel_tree\": range(1,6,1),\r\n",
    "#               # \"reg_alpha\": np.logspace(-3,3,300),\r\n",
    "#               # \"reg_lambda\": np.logspace(-3,3,300)\r\n",
    "#             }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# model = HistGradientBoostingRegressor(random_state=11111,verbose=1)\r\n",
    "# param_grid = {\"max_leaf_nodes\" : [15,31,63],\r\n",
    "#               \"learning_rate\": [0.1,0.01,0.001],\r\n",
    "#               \"max_iter\": [100,300],\r\n",
    "#               \"min_samples_leaf\": [10,20,30],\r\n",
    "#               \"l2_regularization\": [0.0,0.1,0.01]\r\n",
    "#              }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# models = []\r\n",
    "\r\n",
    "# for train_idxs, val_idxs in ss.split(inputs):\r\n",
    "#    X_train, train_targets = inputs.iloc[train_idxs], targets.iloc[train_idxs]\r\n",
    "#    X_val, val_targets = inputs.iloc[val_idxs], targets.iloc[val_idxs]\r\n",
    "#    X_train = np.ascontiguousarray(X_train).reshape(-1,2)\r\n",
    "#    train_targets = np.ascontiguousarray(train_targets).ravel()\r\n",
    "#    X_val = np.ascontiguousarray(X_val).reshape(-1,2)\r\n",
    "#    val_targets = np.ascontiguousarray(val_targets).ravel()\r\n",
    "#    grid_search = HalvingGridSearchCV(model, param_grid,factor=2,random_state=11111,n_jobs=-1,verbose=1).fit(X_train, train_targets)\r\n",
    "#    model, train_R2, train_RMSPE, val_R2, val_RMSPE = train_and_evaluate(X_train, \r\n",
    "#                                                    train_targets, \r\n",
    "#                                                    X_val, \r\n",
    "#                                                    val_targets, \r\n",
    "#                                                    **grid_search.best_params_)\r\n",
    "#    models.append(model)\r\n",
    "#    print('Train R2: {}, Train RMSPE: {}, Validation R2: {}, Validation RMSPE: {}'.format(train_R2, train_RMSPE, val_R2, val_RMSPE))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# modelc = RandomForestRegressor(random_state=11111,verbose=1,n_jobs=-1)\r\n",
    "# param_grid = {\"n_estimators\": [50,100,500],\r\n",
    "#               \"min_samples_split\": [2,4,6],\r\n",
    "#               \"min_samples_leaf\": [1,2,4],\r\n",
    "#             #   \"min_impurity_decrease\": [0.0,0.01,0.001],\r\n",
    "#             #   \"oob_score\": [True,False],\r\n",
    "#             #   \"ccp_alpha\": [0.0,0.01,0.001],\r\n",
    "#              }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "params = {'num_leaves':31}\r\n",
    "modelc = LGBMRegressor(random_state=11111,n_jobs=-1,silent=False,metric='rmse',force_col_wise=True,**params)#,bagging_freq= 5, bagging_fraction= 0.75)\r\n",
    "param_grid = {\"boosting_type\": ['gbdt','goss','dart'],\r\n",
    "              \"learning_rate\" : [0.1,0.01,0.001],\r\n",
    "              \"n_estimators\": [50,100,300],\r\n",
    "              \"min_child_samples\": [10,20,30],\r\n",
    "              \"min_split_gain\": [0.0,0.001,0.1],\r\n",
    "            }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "X_train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(214466, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "#without early stopping\r\n",
    "params = grid_search.best_params_\r\n",
    "model, train_R2, train_RMSPE, val_R2, val_RMSPE = train_and_evaluate(X_train, \r\n",
    "                                                train_targets, \r\n",
    "                                                X_val, \r\n",
    "                                                val_targets, \r\n",
    "                                                **params)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 214466, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 0.003882\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "#with early stopping\r\n",
    "params = grid_search.best_params_\r\n",
    "model, train_R2, train_RMSPE, val_R2, val_RMSPE = train_and_evaluate(X_train, \r\n",
    "                                                train_targets, \r\n",
    "                                                X_val, \r\n",
    "                                                val_targets, \r\n",
    "                                                **params)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 214466, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 0.003882\n",
      "[1]\tvalid_0's rmse: 0.00279718\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 0.00268065\n",
      "[3]\tvalid_0's rmse: 0.00258229\n",
      "[4]\tvalid_0's rmse: 0.0024995\n",
      "[5]\tvalid_0's rmse: 0.00243036\n",
      "[6]\tvalid_0's rmse: 0.00237282\n",
      "[7]\tvalid_0's rmse: 0.00232505\n",
      "[8]\tvalid_0's rmse: 0.00228531\n",
      "[9]\tvalid_0's rmse: 0.00225271\n",
      "[10]\tvalid_0's rmse: 0.00222552\n",
      "[11]\tvalid_0's rmse: 0.00220341\n",
      "[12]\tvalid_0's rmse: 0.00218524\n",
      "[13]\tvalid_0's rmse: 0.00217036\n",
      "[14]\tvalid_0's rmse: 0.00215838\n",
      "[15]\tvalid_0's rmse: 0.00214826\n",
      "[16]\tvalid_0's rmse: 0.00214009\n",
      "[17]\tvalid_0's rmse: 0.00213362\n",
      "[18]\tvalid_0's rmse: 0.00212821\n",
      "[19]\tvalid_0's rmse: 0.00212385\n",
      "[20]\tvalid_0's rmse: 0.00212023\n",
      "[21]\tvalid_0's rmse: 0.00211729\n",
      "[22]\tvalid_0's rmse: 0.00211505\n",
      "[23]\tvalid_0's rmse: 0.0021131\n",
      "[24]\tvalid_0's rmse: 0.0021116\n",
      "[25]\tvalid_0's rmse: 0.00211031\n",
      "[26]\tvalid_0's rmse: 0.00210935\n",
      "[27]\tvalid_0's rmse: 0.0021085\n",
      "[28]\tvalid_0's rmse: 0.00210784\n",
      "[29]\tvalid_0's rmse: 0.00210724\n",
      "[30]\tvalid_0's rmse: 0.0021069\n",
      "[31]\tvalid_0's rmse: 0.00210655\n",
      "[32]\tvalid_0's rmse: 0.00210631\n",
      "[33]\tvalid_0's rmse: 0.00210617\n",
      "[34]\tvalid_0's rmse: 0.00210597\n",
      "[35]\tvalid_0's rmse: 0.00210582\n",
      "[36]\tvalid_0's rmse: 0.00210572\n",
      "[37]\tvalid_0's rmse: 0.00210554\n",
      "[38]\tvalid_0's rmse: 0.00210552\n",
      "[39]\tvalid_0's rmse: 0.00210553\n",
      "[40]\tvalid_0's rmse: 0.00210543\n",
      "[41]\tvalid_0's rmse: 0.00210544\n",
      "[42]\tvalid_0's rmse: 0.00210544\n",
      "[43]\tvalid_0's rmse: 0.00210548\n",
      "[44]\tvalid_0's rmse: 0.00210551\n",
      "[45]\tvalid_0's rmse: 0.00210551\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's rmse: 0.00210543\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "models = []\r\n",
    "model_params = []\r\n",
    "grid_params = []\r\n",
    "for train_idxs, val_idxs in ss.split(poly_inputs):\r\n",
    "   X_train, train_targets = poly_inputs.iloc[train_idxs], targets.iloc[train_idxs]\r\n",
    "   X_val, val_targets = poly_inputs.iloc[val_idxs], targets.iloc[val_idxs]\r\n",
    "   X_train = np.ascontiguousarray(X_train).reshape(-1,10)\r\n",
    "   train_targets = np.ascontiguousarray(train_targets).ravel()\r\n",
    "   X_val = np.ascontiguousarray(X_val).reshape(-1,10)\r\n",
    "   val_targets = np.ascontiguousarray(val_targets).ravel()\r\n",
    "   grid_search = HalvingGridSearchCV(modelc, param_grid,n_jobs=-1,verbose=1,return_train_score=True,random_state=11111,factor=3,min_resources=1000,error_score='raise').fit(X_train, train_targets)\r\n",
    "   params = grid_search.best_params_\r\n",
    "   model, train_R2, train_RMSPE, val_R2, val_RMSPE = train_and_evaluate(X_train, \r\n",
    "                                                   train_targets, \r\n",
    "                                                   X_val, \r\n",
    "                                                   val_targets, \r\n",
    "                                                   **params)\r\n",
    "   models.append(model)\r\n",
    "   model_params.append(model.get_params())\r\n",
    "   grid_params.append(grid_search.best_params_)\r\n",
    "   print('Train R2: {}, Train RMSPE: {}, Validation R2: {}, Validation RMSPE: {}'.format(train_R2, train_RMSPE, val_R2, val_RMSPE))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 1000\n",
      "max_resources_: 214466\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 243\n",
      "n_resources: 1000\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BAAGYU~1\\AppData\\Local\\Temp/ipykernel_12992/2191501741.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m    \u001b[0mX_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m    \u001b[0mval_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m    \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHalvingGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m11111\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_resources\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m    \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m    model, train_R2, train_RMSPE, val_R2, val_RMSPE = train_and_evaluate(X_train, \n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_samples_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;31m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    365\u001b[0m             }\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m             results = evaluate_candidates(\n\u001b[0m\u001b[0;32m    368\u001b[0m                 \u001b[0mcandidate_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmore_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmore_results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import lightgbm as lgb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_data = lgb.Dataset(poly_inputs.values,label=targets.values,free_raw_data=True)\r\n",
    "validation_data = lgb.Dataset('validation.svm', reference=train_data,free_raw_data=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lgb.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "models"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[LGBMRegressor(metric='rmse', random_state=11111, silent=False),\n",
       " LGBMRegressor(metric='rmse', random_state=11111, silent=False),\n",
       " LGBMRegressor(metric='rmse', random_state=11111, silent=False),\n",
       " LGBMRegressor(metric='rmse', random_state=11111, silent=False),\n",
       " LGBMRegressor(metric='rmse', random_state=11111, silent=False),\n",
       " LGBMRegressor(metric='rmse', random_state=11111, silent=False)]"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "print(modelc.get_params()) #HalvingGridSearch"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 11111, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': False, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'metric': 'rmse'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "modelc.feature_importances_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  0, 449, 286,   0, 165,   0,   0, 278, 232,   0])"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "modelc.objective_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'regression'"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "df_gd_par = pd.DataFrame(grid_params)\r\n",
    "df_md_par = pd.DataFrame(model_params)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "df_gd_par"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boosting_type</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>min_split_gain</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  boosting_type  learning_rate  min_child_samples  min_split_gain  \\\n",
       "0          goss           0.01                 20             0.0   \n",
       "1          goss           0.01                 20             0.0   \n",
       "2          goss           0.01                 20             0.0   \n",
       "3          goss           0.01                 10             0.0   \n",
       "4          goss           0.01                 10             0.0   \n",
       "5          goss           0.01                 10             0.0   \n",
       "\n",
       "   n_estimators  \n",
       "0           300  \n",
       "1           300  \n",
       "2           300  \n",
       "3           300  \n",
       "4           300  \n",
       "5           300  "
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "df_md_par"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boosting_type</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>importance_type</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>min_split_gain</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>objective</th>\n",
       "      <th>random_state</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>silent</th>\n",
       "      <th>subsample</th>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <th>subsample_freq</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>split</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>11111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>rmse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>split</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>11111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>rmse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>split</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>11111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>rmse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>split</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>11111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>rmse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>split</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>11111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>rmse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>split</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>11111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>rmse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  boosting_type class_weight  colsample_bytree importance_type  learning_rate  \\\n",
       "0          gbdt         None               1.0           split            0.1   \n",
       "1          gbdt         None               1.0           split            0.1   \n",
       "2          gbdt         None               1.0           split            0.1   \n",
       "3          gbdt         None               1.0           split            0.1   \n",
       "4          gbdt         None               1.0           split            0.1   \n",
       "5          gbdt         None               1.0           split            0.1   \n",
       "\n",
       "   max_depth  min_child_samples  min_child_weight  min_split_gain  \\\n",
       "0         -1                 20             0.001             0.0   \n",
       "1         -1                 20             0.001             0.0   \n",
       "2         -1                 20             0.001             0.0   \n",
       "3         -1                 20             0.001             0.0   \n",
       "4         -1                 20             0.001             0.0   \n",
       "5         -1                 20             0.001             0.0   \n",
       "\n",
       "   n_estimators  ...  num_leaves  objective random_state  reg_alpha  \\\n",
       "0           100  ...          31       None        11111        0.0   \n",
       "1           100  ...          31       None        11111        0.0   \n",
       "2           100  ...          31       None        11111        0.0   \n",
       "3           100  ...          31       None        11111        0.0   \n",
       "4           100  ...          31       None        11111        0.0   \n",
       "5           100  ...          31       None        11111        0.0   \n",
       "\n",
       "   reg_lambda  silent  subsample  subsample_for_bin  subsample_freq  metric  \n",
       "0         0.0   False        1.0             200000               0    rmse  \n",
       "1         0.0   False        1.0             200000               0    rmse  \n",
       "2         0.0   False        1.0             200000               0    rmse  \n",
       "3         0.0   False        1.0             200000               0    rmse  \n",
       "4         0.0   False        1.0             200000               0    rmse  \n",
       "5         0.0   False        1.0             200000               0    rmse  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "models = []\r\n",
    "\r\n",
    "for train_idxs, val_idxs in ss.split(poly_inputs):\r\n",
    "   X_train, train_targets = poly_inputs.iloc[train_idxs], targets.iloc[train_idxs]\r\n",
    "   X_val, val_targets = poly_inputs.iloc[val_idxs], targets.iloc[val_idxs]\r\n",
    "   X_train = np.ascontiguousarray(X_train).reshape(-1,10)\r\n",
    "   train_targets = np.ascontiguousarray(train_targets).ravel()\r\n",
    "   X_val = np.ascontiguousarray(X_val).reshape(-1,10)\r\n",
    "   val_targets = np.ascontiguousarray(val_targets).ravel()\r\n",
    "   grid_search = GridSearchCV(modelc, param_grid,n_jobs=-1,verbose=1,return_train_score=True,error_score='raise').fit(X_train, train_targets)\r\n",
    "   model, train_R2, train_RMSPE, val_R2, val_RMSPE = train_and_evaluate(X_train, \r\n",
    "                                                   train_targets, \r\n",
    "                                                   X_val, \r\n",
    "                                                   val_targets, \r\n",
    "                                                   **grid_search.best_params_)\r\n",
    "   models.append(modelc)\r\n",
    "   print('Train R2: {}, Train RMSPE: {}, Validation R2: {}, Validation RMSPE: {}'.format(train_R2, train_RMSPE, val_R2, val_RMSPE))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BAAGYU~1\\AppData\\Local\\Temp/ipykernel_6720/615206028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m    \u001b[0mX_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m    \u001b[0mval_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m    \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m    model, train_R2, train_RMSPE, val_R2, val_RMSPE = train_and_evaluate(X_train, \n\u001b[0;32m     12\u001b[0m                                                    \u001b[0mtrain_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}