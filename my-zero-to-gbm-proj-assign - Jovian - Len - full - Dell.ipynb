{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##### my-zero-to-gbm-proj-assign"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optiver Realized Volatility Prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This dataset contains stock market data relevant to the practical execution of trades in the financial markets. In particular, it includes order book snapshots and executed trades. With one second resolution, it provides a uniquely fine grained look at the micro-structure of modern financial markets.\r\n",
    "\r\n",
    "This is a code competition where only the first few rows of the test set are available for download. The rows that are visible are intended to illustrate the hidden test set format and folder structure. The remainder will only be available to your notebook when it is submitted. The hidden test set contains data that can be used to construct features to predict roughly 150,000 target values. Loading the entire dataset will take slightly more than 3 GB of memory, by our estimation.\r\n",
    "\r\n",
    "This is also a forecasting competition, where the final private leaderboard will be determined using data gathered after the training period closes, which means that the public and private leaderboards will have zero overlap. During the active training stage of the competition a large fraction of the test data will be filler, intended only to ensure the hidden dataset has approximately the same size as the actual test data. The filler data will be removed entirely during the forecasting phase of the competition and replaced with real"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install jovian --upgrade --quiet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import jovian"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data Description\r\n",
    "\r\n",
    "book_[train/test].parquet A parquet file partitioned by stock_id. Provides order book data on the most competitive buy and sell orders entered into the market. The top two levels of the book are shared. The first level of the book will be more competitive in price terms, it will then receive execution priority over the second level.\r\n",
    "\r\n",
    "stock_id - ID code for the stock. Not all stock IDs exist in every time bucket. Parquet coerces this column to the categorical data type when loaded; you may wish to convert it to int8.\r\n",
    "time_id - ID code for the time bucket. Time IDs are not necessarily sequential but are consistent across all stocks.\r\n",
    "seconds_in_bucket - Number of seconds from the start of the bucket, always starting from 0.\r\n",
    "bid_price[1/2] - Normalized prices of the most/second most competitive buy level.\r\n",
    "ask_price[1/2] - Normalized prices of the most/second most competitive sell level.\r\n",
    "bid_size[1/2] - The number of shares on the most/second most competitive buy level.\r\n",
    "ask_size[1/2] - The number of shares on the most/second most competitive sell level.\r\n",
    "trade_[train/test].parquet A parquet file partitioned by stock_id. Contains data on trades that actually executed. Usually, in the market, there are more passive buy/sell intention updates (book updates) than actual trades, therefore one may expect this file to be more sparse than the order book.\r\n",
    "\r\n",
    "stock_id - Same as above.\r\n",
    "time_id - Same as above.\r\n",
    "seconds_in_bucket - Same as above. Note that since trade and book data are taken from the same time window and trade data is more sparse in general, this field is not necessarily starting from 0.\r\n",
    "price - The average price of executed transactions happening in one second. Prices have been normalized and the average has been weighted by the number of shares traded in each transaction.\r\n",
    "size - The sum number of shares traded.\r\n",
    "order_count - The number of unique trade orders taking place.\r\n",
    "train.csv The ground truth values for the training set.\r\n",
    "\r\n",
    "stock_id - Same as above, but since this is a csv the column will load as an integer instead of categorical.\r\n",
    "time_id - Same as above.\r\n",
    "target - The realized volatility computed over the 10 minute window following the feature data under the same stock/time_id. There is no overlap between feature and target data. You can find more info in our tutorial notebook.\r\n",
    "test.csv Provides the mapping between the other data files and the submission file. As with other test files, most of the data is only available to your notebook upon submission with just the first few rows available for download.\r\n",
    "\r\n",
    "stock_id - Same as above.\r\n",
    "time_id - Same as above.\r\n",
    "row_id - Unique identifier for the submission row. There is one row for each existing time ID/stock ID pair. Each time window is not necessarily containing every individual stock.\r\n",
    "sample_submission.csv - A sample submission file in the correct format.\r\n",
    "\r\n",
    "row_id - Same as in test.csv.\r\n",
    "target - Same definition as in train.csv. The benchmark is using the median target value from train.csv."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Execute this to save new versions of the notebook\r\n",
    "#jovian.commit(project=\"my-zero-to-gbm-proj-assign\")\r\n",
    "jovian.commit(filename=\"my-zero-to-gbm-proj-assign.ipynb\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import plotly.express as px\r\n",
    "#train = pd.read_csv('../../../data/optiver-realized-volatility-prediction/train.csv')\r\n",
    "train = pd.read_csv('d:\\\\optiver-realized-volatility-prediction\\\\train.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 428932 entries, 0 to 428931\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   stock_id  428932 non-null  int64  \n",
      " 1   time_id   428932 non-null  int64  \n",
      " 2   target    428932 non-null  float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 9.8 MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import glob\r\n",
    "list_order_book_file_train = glob.glob('d:\\\\optiver-realized-volatility-prediction\\\\book_train.parquet/*')\r\n",
    "list_trade_book_file_train = glob.glob('d:\\\\optiver-realized-volatility-prediction\\\\trade_train.parquet/*')\r\n",
    "#list_order_book_file_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# def compute_wap(df_stock_book):\r\n",
    "#        df_stock_book['bid_price'] = (df_stock_book['bid_price1'] * df_stock_book['bid_size1'] + df_stock_book['bid_price2'] * df_stock_book['bid_size2'])/(df_stock_book['bid_size1'] + df_stock_book['bid_size2'])\r\n",
    "#        df_stock_book['bid_size'] = (df_stock_book['bid_size1'] + df_stock_book['bid_size2'])\r\n",
    "\r\n",
    "#        df_stock_book['ask_price'] = (df_stock_book['ask_price1'] * df_stock_book['ask_size1'] + df_stock_book['ask_price2'] * df_stock_book['ask_size2'])/(df_stock_book['ask_size1'] + df_stock_book['ask_size2'])\r\n",
    "#        df_stock_book['ask_size'] = (df_stock_book['ask_size1'] + df_stock_book['ask_size2'])\r\n",
    "\r\n",
    "#        df_stock_book['wap'] = (df_stock_book['bid_price'] * df_stock_book['ask_size'] + df_stock_book['ask_price'] * df_stock_book['bid_size']) / (df_stock_book['bid_size'] +  df_stock_book['ask_size'])\r\n",
    "#        return df_stock_book['wap']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_order_book = pd.DataFrame()\r\n",
    "for file in list_order_book_file_train:\r\n",
    "     df_stock_book = pd.read_parquet(file)\r\n",
    "     df_stock_book['stock_id'] = file.split('=')[1]\r\n",
    "     df_order_book = pd.concat([df_order_book,df_stock_book])\r\n",
    "\r\n",
    "\r\n",
    "df_trade_book = pd.DataFrame()\r\n",
    "for file in list_trade_book_file_train:\r\n",
    "     df_stock_book = pd.read_parquet(file)\r\n",
    "     df_stock_book['stock_id'] = file.split('=')[1]\r\n",
    "     df_trade_book = pd.concat([df_trade_book,df_stock_book])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# with open('book_index.csv','w+') as f:\r\n",
    "#     for items in list(df_order_book_50.index):\r\n",
    "#         f.write('%s\\n' %items)\r\n",
    "#new_index\r\n",
    "# df_order_book_5.reset_index(inplace=True,drop=True)\r\n",
    "# df_trade_book_5.reset_index(inplace=True,drop=True)\r\n",
    "\r\n",
    "df_order_book.reset_index(inplace=True,drop=True)\r\n",
    "df_trade_book.reset_index(inplace=True,drop=True)\r\n",
    "\r\n",
    "#df_order_book_50.head(-1)\r\n",
    "#df_order_book_50[df_order_book_50.index != df_order_book_50['index']]\r\n",
    "#(72311913, 11)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_order_book['stock_id'] = df_order_book['stock_id'].astype('int8')\r\n",
    "df_trade_book['stock_id'] = df_trade_book['stock_id'].astype('int8')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# df_order_book['order_wap'] = (((df_order_book['bid_price1'] * df_order_book['bid_size1'] + df_order_book['bid_price2'] * df_order_book['bid_size2'])/(df_order_book['bid_size1'] + df_order_book['bid_size2']) * (df_order_book['ask_size1'] + df_order_book['ask_size2'])) + ((df_order_book['ask_price1'] * df_order_book['ask_size1'] + df_order_book['ask_price2'] * df_order_book['ask_size2'])/(df_order_book['ask_size1'] + df_order_book['ask_size2'])) * (df_order_book['bid_size1'] + df_order_book['bid_size2'])) / ((df_order_book['bid_size1'] + df_order_book['bid_size2']) +  (df_order_book['ask_size1'] + df_order_book['ask_size2']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# df_order_book['order_wap'] = ((((df_order_book['bid_price1'] * df_order_book['bid_size1'] + df_order_book['bid_price2'] * \r\n",
    "#     df_order_book['bid_size2'])/(df_order_book['bid_size1'] + df_order_book['bid_size2'])) * (df_order_book['ask_size1'] + \r\n",
    "#     df_order_book['ask_size2'])) + (((df_order_book['ask_price1'] * df_order_book['ask_size1'] + df_order_book['ask_price2'] * \r\n",
    "#     df_order_book['ask_size2'])/(df_order_book['ask_size1'] + df_order_book['ask_size2'])) * (df_order_book['bid_size1'] + \r\n",
    "#     df_order_book['bid_size2'])) / ((df_order_book['bid_size1'] + df_order_book['bid_size2']) +  (df_order_book['ask_size1'] + \r\n",
    "#     df_order_book['ask_size2']))).astype('float32')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_order_book['order_wap'] = ((((df_order_book['bid_price1'].values * df_order_book['bid_size1'].values + df_order_book['bid_price2'].values * \r\n",
    "    df_order_book['bid_size2'].values)/(df_order_book['bid_size1'].values + df_order_book['bid_size2'].values)) * (df_order_book['ask_size1'].values + \r\n",
    "    df_order_book['ask_size2'].values)) + (((df_order_book['ask_price1'].values * df_order_book['ask_size1'].values + df_order_book['ask_price2'].values * \r\n",
    "    df_order_book['ask_size2'].values)/(df_order_book['ask_size1'].values + df_order_book['ask_size2'].values)) * (df_order_book['bid_size1'].values + \r\n",
    "    df_order_book['bid_size2'].values)) / ((df_order_book['bid_size1'].values + df_order_book['bid_size2'].values) +  (df_order_book['ask_size1'].values + \r\n",
    "    df_order_book['ask_size2'].values))).astype('float32')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df_order_book.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 167253289 entries, 0 to 167253288\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   time_id            int16  \n",
      " 1   seconds_in_bucket  int16  \n",
      " 2   bid_price1         float32\n",
      " 3   ask_price1         float32\n",
      " 4   bid_price2         float32\n",
      " 5   ask_price2         float32\n",
      " 6   bid_size1          int32  \n",
      " 7   ask_size1          int32  \n",
      " 8   bid_size2          int32  \n",
      " 9   ask_size2          int32  \n",
      " 10  stock_id           int8   \n",
      " 11  order_wap          float32\n",
      "dtypes: float32(5), int16(2), int32(4), int8(1)\n",
      "memory usage: 6.4 GB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# grouped = df_order_book.groupby(['time_id','stock_id'])['seconds_in_bucket','order_wap']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# s3 =pd.DataFrame(df_order_book[['time_id','stock_id','seconds_in_bucket','order_wap']])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "new_index = pd.Index(np.arange(0,600), name=\"seconds_in_bucket\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# s3=grouped.apply(lambda x : x.set_index('seconds_in_bucket').reindex(new_index))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def log_return(list_stock_prices):\r\n",
    "    return np.log(list_stock_prices).diff()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# s3.loc(axis=0)[:,:,0].isna().sum()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#Below operation is not required because there are no zero seconds records that have null values \r\n",
    "# bf = s2.groupby(['time_id','stock_id'])\r\n",
    "# bf['price'].first()\r\n",
    "# s2.loc[s2.index.get_level_values(2)==0,'price'] = bf['price'].first()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# s3.fillna(method='ffill',inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# s3.isna().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# s3['log_return'] = s3.groupby(['time_id','stock_id'])['order_wap'].apply(log_return)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# s3.loc(axis=0)[:,:,0].isna().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\r\n",
    "def order_volatility(series_log_return):\r\n",
    "    return np.sqrt(np.sum(series_log_return**2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# df_realized_vol_per_stock =  pd.DataFrame(s3[~s3['log_return'].isnull()]['log_return'].groupby(['time_id','stock_id']).agg(order_volatility))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# df_realized_vol_per_stock.isna().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df_trade_book['scc'] = (df_trade_book['size']/df_trade_book['order_count']).astype('float16')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df_trade_book['price'].corr(df_trade_book['scc'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.00265647386908627"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "df_trade_book.info(),df_order_book.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38382741 entries, 0 to 38382740\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   time_id            int16  \n",
      " 1   seconds_in_bucket  int16  \n",
      " 2   price              float32\n",
      " 3   size               int32  \n",
      " 4   order_count        int16  \n",
      " 5   stock_id           int8   \n",
      " 6   scc                float16\n",
      "dtypes: float16(1), float32(1), int16(3), int32(1), int8(1)\n",
      "memory usage: 622.3 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 167253289 entries, 0 to 167253288\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   time_id            int16  \n",
      " 1   seconds_in_bucket  int16  \n",
      " 2   bid_price1         float32\n",
      " 3   ask_price1         float32\n",
      " 4   bid_price2         float32\n",
      " 5   ask_price2         float32\n",
      " 6   bid_size1          int32  \n",
      " 7   ask_size1          int32  \n",
      " 8   bid_size2          int32  \n",
      " 9   ask_size2          int32  \n",
      " 10  stock_id           int8   \n",
      " 11  order_wap          float32\n",
      "dtypes: float32(5), int16(2), int32(4), int8(1)\n",
      "memory usage: 6.4 GB\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "df_order_trade_merged = pd.merge(\r\n",
    "    df_order_book[['time_id','stock_id','seconds_in_bucket','order_wap']],\r\n",
    "    df_trade_book[['time_id','stock_id','seconds_in_bucket','price','scc']],\r\n",
    "    how=\"outer\",\r\n",
    "    on=['time_id','stock_id','seconds_in_bucket'],\r\n",
    "    sort=True,\r\n",
    "    copy=False,\r\n",
    "    indicator=False,\r\n",
    "    validate='m:m'\r\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "grouped = df_order_trade_merged.groupby(['time_id','stock_id'])['seconds_in_bucket','order_wap','price','scc']"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\BAAGYU~1\\AppData\\Local\\Temp/ipykernel_12076/1842595998.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  grouped = df_order_trade_merged.groupby(['time_id','stock_id'])['seconds_in_bucket','order_wap','price','scc']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "s1 = grouped.apply(lambda x : x.set_index('seconds_in_bucket').reindex(new_index))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "s1.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(257359200, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# #grouped_trade = df_trade_book.groupby(['time_id','stock_id'])['seconds_in_bucket','price','scc']\r\n",
    "# s4 = df_trade_book.groupby(['time_id','stock_id'])['seconds_in_bucket','price','scc'].apply(lambda x : x.set_index('seconds_in_bucket').reindex(new_index))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "s1.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 257359200 entries, (5, 0, 0) to (32767, 126, 599)\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   order_wap  float32\n",
      " 1   price      float32\n",
      " 2   scc        float16\n",
      "dtypes: float16(1), float32(2)\n",
      "memory usage: 3.6 GB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "s1.isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "order_wap     90105911\n",
       "price        218976459\n",
       "scc          218976459\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "s1.loc(axis=0)[:,:,0].isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "order_wap         0\n",
       "price        334129\n",
       "scc          334129\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "bf = s1.groupby(['time_id','stock_id'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "bf.first().isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "order_wap     0\n",
       "price        19\n",
       "scc          19\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "s1.loc[s1.index.get_level_values(2)==0,['order_wap','price','scc']] = bf.first()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "s1.loc(axis=0)[:,:,0].isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "order_wap     0\n",
       "price        19\n",
       "scc          19\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "s1.loc(axis=0)[:,:,0]['price'].isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "s1.loc(axis=0)[:,:,0][s1.loc(axis=0)[:,:,0]['price'].isna()]['price']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "time_id  stock_id  seconds_in_bucket\n",
       "62       37        0                   NaN\n",
       "985      31        0                   NaN\n",
       "3987     31        0                   NaN\n",
       "5539     31        0                   NaN\n",
       "5629     31        0                   NaN\n",
       "6197     31        0                   NaN\n",
       "8524     18        0                   NaN\n",
       "8753     31        0                   NaN\n",
       "8840     31        0                   NaN\n",
       "9208     31        0                   NaN\n",
       "9664     103       0                   NaN\n",
       "12011    31        0                   NaN\n",
       "13377    31        0                   NaN\n",
       "13663    31        0                   NaN\n",
       "15010    31        0                   NaN\n",
       "20017    31        0                   NaN\n",
       "22498    31        0                   NaN\n",
       "28186    31        0                   NaN\n",
       "32174    31        0                   NaN\n",
       "Name: price, dtype: float32"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "s1.loc(axis=0)[62,37,:]['price'].isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "s1.loc(axis=0)[:,:,0][s1.loc(axis=0)[:,:,0]['price'].isna()]['price'].index.unique(level=1).values"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 37,  31,  18, 103], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "s1.loc(axis=0)[:,31,0]['price'].mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9998831152915955"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# s1.loc(axis=0)[:,:,0][s1.loc(axis=0)[:,:,0]['price'].isna()]['price'].transform(lambda x: s1.loc(axis=0)[:,x.index.get_level_values(1),0]['price'].mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# s1.loc(axis=0)[:,:,0][s1.loc(axis=0)[:,:,0]['price'].isna()][['price','scc']].apply(lambda x: s1.loc(axis=0)[:,x.index.get_level_values(1),0]['price'].mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "source": [
    "s1.loc(axis=0)[:,:,0][['price','scc']][s1.loc(axis=0)[:,:,0]['price'].isna()] = b.values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "s1.loc(axis=0)[:,:,0][s1.loc(axis=0)[:,:,0]['price'].isna()][['price','scc']]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>scc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <th>37</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8524</th>\n",
       "      <th>18</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8753</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8840</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9208</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9664</th>\n",
       "      <th>103</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12011</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13377</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13663</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15010</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20017</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22498</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28186</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32174</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    price  scc\n",
       "time_id stock_id seconds_in_bucket            \n",
       "62      37       0                    NaN  NaN\n",
       "985     31       0                    NaN  NaN\n",
       "3987    31       0                    NaN  NaN\n",
       "5539    31       0                    NaN  NaN\n",
       "5629    31       0                    NaN  NaN\n",
       "6197    31       0                    NaN  NaN\n",
       "8524    18       0                    NaN  NaN\n",
       "8753    31       0                    NaN  NaN\n",
       "8840    31       0                    NaN  NaN\n",
       "9208    31       0                    NaN  NaN\n",
       "9664    103      0                    NaN  NaN\n",
       "12011   31       0                    NaN  NaN\n",
       "13377   31       0                    NaN  NaN\n",
       "13663   31       0                    NaN  NaN\n",
       "15010   31       0                    NaN  NaN\n",
       "20017   31       0                    NaN  NaN\n",
       "22498   31       0                    NaN  NaN\n",
       "28186   31       0                    NaN  NaN\n",
       "32174   31       0                    NaN  NaN"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "a = s1.loc(axis=0)[:,:,0][s1.loc(axis=0)[:,:,0]['price'].isna()][['price','scc']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def price_scc(col):\r\n",
    "    #return  s1.loc(axis=0)[:,col.name[1],0][col.index[0]].mean(),s1.loc(axis=0)[:,col.name[1],:][col.index[1]].mean()\r\n",
    "    #return s1.loc(axis=0)[:,col.name[1],0].groupby(level=[1,2])['price'].mean(), s1.loc(axis=0)[:,col.name[1],0].groupby(level=[1,2])['scc'].mean()\r\n",
    "    return s1.loc(axis=0)[:,col.name[1],0]['price'].mean(), np.asscalar(s1.loc(axis=0)[:,col.name[1],0]['scc'].mean(skipna=True,level=[1,2]).values)\r\n",
    "    #return col.name[1] , col.index[0]\r\n",
    "    #row.scc = s1.loc(axis=0)[:,row.index.get_level_values(1),0]['scc'].mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "b = a.transform(price_scc ,axis=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\BAAGYU~1\\AppData\\Local\\Temp/ipykernel_12076/3509852037.py:4: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
      "  return s1.loc(axis=0)[:,col.name[1],0]['price'].mean(), np.asscalar(s1.loc(axis=0)[:,col.name[1],0]['scc'].mean(skipna=True,level=[1,2]).values)\n",
      "C:\\Users\\BAAGYU~1\\AppData\\Local\\Temp/ipykernel_12076/3509852037.py:4: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  return s1.loc(axis=0)[:,col.name[1],0]['price'].mean(), np.asscalar(s1.loc(axis=0)[:,col.name[1],0]['scc'].mean(skipna=True,level=[1,2]).values)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "b"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>scc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <th>37</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999967</td>\n",
       "      <td>12.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8524</th>\n",
       "      <th>18</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999964</td>\n",
       "      <td>18.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8753</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8840</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9208</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9664</th>\n",
       "      <th>103</th>\n",
       "      <th>0</th>\n",
       "      <td>1.000041</td>\n",
       "      <td>19.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12011</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13377</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13663</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15010</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20017</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22498</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28186</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32174</th>\n",
       "      <th>31</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999883</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       price         scc\n",
       "time_id stock_id seconds_in_bucket                      \n",
       "62      37       0                  0.999967   12.804688\n",
       "985     31       0                  0.999883  581.500000\n",
       "3987    31       0                  0.999883  581.500000\n",
       "5539    31       0                  0.999883  581.500000\n",
       "5629    31       0                  0.999883  581.500000\n",
       "6197    31       0                  0.999883  581.500000\n",
       "8524    18       0                  0.999964   18.078125\n",
       "8753    31       0                  0.999883  581.500000\n",
       "8840    31       0                  0.999883  581.500000\n",
       "9208    31       0                  0.999883  581.500000\n",
       "9664    103      0                  1.000041   19.921875\n",
       "12011   31       0                  0.999883  581.500000\n",
       "13377   31       0                  0.999883  581.500000\n",
       "13663   31       0                  0.999883  581.500000\n",
       "15010   31       0                  0.999883  581.500000\n",
       "20017   31       0                  0.999883  581.500000\n",
       "22498   31       0                  0.999883  581.500000\n",
       "28186   31       0                  0.999883  581.500000\n",
       "32174   31       0                  0.999883  581.500000"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "s1.fillna(b,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "source": [
    "s1.isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "order_wap     90105911\n",
       "price        218642349\n",
       "scc          218642349\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 313
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "source": [
    "s1.loc(axis=0)[:,:,0].isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "order_wap     0\n",
       "price        19\n",
       "scc          19\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 314
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "df_order_book['stock_id'] = df_order_book['stock_id'].astype('int8')\r\n",
    "df_order_book[['time_id','seconds_in_bucket']] = df_order_book[['time_id','seconds_in_bucket']].astype('int16')\r\n",
    "df_order_book[['bid_size1','ask_size1','bid_size2','ask_size2']] = df_order_book[['bid_size1','ask_size1','bid_size2','ask_size2']].astype('int32')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "#grouped = df_order_trade_merged.groupby(['time_id','stock_id'])\r\n",
    "grouped = df_order_book.groupby(['time_id','stock_id'])\r\n",
    "\r\n",
    "#df_order_book_50_idxed.index.levels[2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import swifter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from distributed import Client\r\n",
    "# create local cluster\r\n",
    "client = Client(n_workers=8)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\client.py:1105: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "+---------+--------+-----------+---------+\n",
      "| Package | client | scheduler | workers |\n",
      "+---------+--------+-----------+---------+\n",
      "| pandas  | 1.3.1  | 1.3.1     | 1.3.0   |\n",
      "+---------+--------+-----------+---------+\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import dask.dataframe as dd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "dd.from_pandas(grouped, npartitions=8).apply(lambda x : x.set_index('seconds_in_bucket').reindex(new_index))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Input must be a pandas DataFrame or Series",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-ed8c8ce05dbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrouped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seconds_in_bucket'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\io\\io.py\u001b[0m in \u001b[0;36mfrom_pandas\u001b[1;34m(data, npartitions, chunksize, sort, name)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_parallel_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input must be a pandas DataFrame or Series\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnpartitions\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Input must be a pandas DataFrame or Series"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# The Dask engine is currently considered experimental, so I use ray\r\n",
    "%env MODIN_ENGINE=ray\r\n",
    "import modin.pandas as mpd\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env: MODIN_ENGINE=ray\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "df_trade_book.values"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5.00000000e+00, 2.10000000e+01, 1.00230134e+00, 3.26000000e+02,\n",
       "        1.20000000e+01, 0.00000000e+00],\n",
       "       [5.00000000e+00, 4.60000000e+01, 1.00277805e+00, 1.28000000e+02,\n",
       "        4.00000000e+00, 0.00000000e+00],\n",
       "       [5.00000000e+00, 5.00000000e+01, 1.00281847e+00, 5.50000000e+01,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [3.27670000e+04, 5.79000000e+02, 9.99797046e-01, 3.00000000e+02,\n",
       "        3.00000000e+00, 9.90000000e+01],\n",
       "       [3.27670000e+04, 5.84000000e+02, 9.99853671e-01, 1.72000000e+02,\n",
       "        2.00000000e+00, 9.90000000e+01],\n",
       "       [3.27670000e+04, 5.92000000e+02, 9.99661803e-01, 4.00000000e+02,\n",
       "        5.00000000e+00, 9.90000000e+01]])"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "gmpd = mpd.dataframe(df_order_book.values)\r\n",
    "grouped = gmpd.groupby(['time_id','stock_id'])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "MemoryError",
     "evalue": "Unable to allocate 13.7 GiB for an array with shape (11, 167253289) and data type float64",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-4989ebfc597b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgmpd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_order_book\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgrouped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgmpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'stock_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  10659\u001b[0m         \"\"\"\n\u001b[0;32m  10660\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10661\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10663\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdeprecate_nonkeyword_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"self\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mas_array\u001b[1;34m(self, transpose, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1460\u001b[0m             \u001b[1;31m# The underlying data was copied within _interleave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1463\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         \u001b[0mitemmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1498\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1499\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 13.7 GiB for an array with shape (11, 167253289) and data type float64"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "s2=grouped.swifter.apply(lambda x : x.set_index('seconds_in_bucket').reindex(new_index))\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute 'swifter'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-86e6d8c84c0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# No use because the missing sequences is not introduced yet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0ms2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswifter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seconds_in_bucket'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;31m# the best of all\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# creates a multiindex(['time_id', 'stock_id','seconds_in_bucket']) and also does not reintroduce the column \"seconds_in_bucket\" as a normal column into the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    908\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m    911\u001b[0m             \u001b[1;34mf\"'{type(self).__name__}' object has no attribute '{attr}'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute 'swifter'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s2.drop(columns=['time_id','stock_id'],inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "s2[['size','order_count']] = s2[['size','order_count']].fillna(0) \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "s2.loc(axis=0)[:,:,0].isna().sum()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "bid_price1         0\n",
       "ask_price1         0\n",
       "bid_price2         0\n",
       "ask_price2         0\n",
       "bid_size1          0\n",
       "ask_size1          0\n",
       "bid_size2          0\n",
       "ask_size2          0\n",
       "price          14413\n",
       "size               0\n",
       "order_count        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "s2.loc(axis=0)[:,:,0][s2.loc(axis=0)[:,:,0]['price'].isna()]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bid_price1</th>\n",
       "      <th>ask_price1</th>\n",
       "      <th>bid_price2</th>\n",
       "      <th>ask_price2</th>\n",
       "      <th>bid_size1</th>\n",
       "      <th>ask_size1</th>\n",
       "      <th>bid_size2</th>\n",
       "      <th>ask_size2</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>order_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>68</th>\n",
       "      <th>0</th>\n",
       "      <td>1.000354</td>\n",
       "      <td>1.000472</td>\n",
       "      <td>1.000236</td>\n",
       "      <td>1.000591</td>\n",
       "      <td>101.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999077</td>\n",
       "      <td>1.000103</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <th>0</th>\n",
       "      <td>1.001884</td>\n",
       "      <td>1.002048</td>\n",
       "      <td>1.001720</td>\n",
       "      <td>1.002211</td>\n",
       "      <td>500.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>2091.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11</th>\n",
       "      <th>68</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999941</td>\n",
       "      <td>1.000059</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>1.000176</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <th>0</th>\n",
       "      <td>0.996471</td>\n",
       "      <td>0.996785</td>\n",
       "      <td>0.996419</td>\n",
       "      <td>0.997569</td>\n",
       "      <td>286.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">32763</th>\n",
       "      <th>68</th>\n",
       "      <th>0</th>\n",
       "      <td>0.998702</td>\n",
       "      <td>0.998975</td>\n",
       "      <td>0.998565</td>\n",
       "      <td>0.999112</td>\n",
       "      <td>123.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <th>0</th>\n",
       "      <td>1.004087</td>\n",
       "      <td>1.004697</td>\n",
       "      <td>1.003721</td>\n",
       "      <td>1.004941</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">32767</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>0.999220</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>408.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <th>0</th>\n",
       "      <td>1.000636</td>\n",
       "      <td>1.000764</td>\n",
       "      <td>1.000509</td>\n",
       "      <td>1.000891</td>\n",
       "      <td>300.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <th>0</th>\n",
       "      <td>0.998934</td>\n",
       "      <td>0.999645</td>\n",
       "      <td>0.998815</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14413 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    bid_price1  ask_price1  bid_price2  \\\n",
       "time_id stock_id seconds_in_bucket                                       \n",
       "5       68       0                    1.000354    1.000472    1.000236   \n",
       "        100      0                    0.999077    1.000103    0.999009   \n",
       "        111      0                    1.001884    1.002048    1.001720   \n",
       "11      68       0                    0.999941    1.000059    0.999824   \n",
       "        81       0                    0.996471    0.996785    0.996419   \n",
       "...                                        ...         ...         ...   \n",
       "32763   68       0                    0.998702    0.998975    0.998565   \n",
       "        100      0                    1.004087    1.004697    1.003721   \n",
       "32767   2        0                    0.999298    0.999454    0.999220   \n",
       "        68       0                    1.000636    1.000764    1.000509   \n",
       "        81       0                    0.998934    0.999645    0.998815   \n",
       "\n",
       "                                    ask_price2  bid_size1  ask_size1  \\\n",
       "time_id stock_id seconds_in_bucket                                     \n",
       "5       68       0                    1.000591      101.0       40.0   \n",
       "        100      0                    1.000239      100.0        7.0   \n",
       "        111      0                    1.002211      500.0      509.0   \n",
       "11      68       0                    1.000176      100.0      200.0   \n",
       "        81       0                    0.997569      286.0      201.0   \n",
       "...                                        ...        ...        ...   \n",
       "32763   68       0                    0.999112      123.0      201.0   \n",
       "        100      0                    1.004941      100.0        9.0   \n",
       "32767   2        0                    0.999532      408.0      300.0   \n",
       "        68       0                    1.000891      300.0      211.0   \n",
       "        81       0                    0.999763      100.0      200.0   \n",
       "\n",
       "                                    bid_size2  ask_size2  price  size  \\\n",
       "time_id stock_id seconds_in_bucket                                      \n",
       "5       68       0                      201.0      321.0    NaN   0.0   \n",
       "        100      0                       64.0      100.0    NaN   0.0   \n",
       "        111      0                      710.0     2091.0    NaN   0.0   \n",
       "11      68       0                      200.0      300.0    NaN   0.0   \n",
       "        81       0                       20.0      100.0    NaN   0.0   \n",
       "...                                       ...        ...    ...   ...   \n",
       "32763   68       0                      396.0      100.0    NaN   0.0   \n",
       "        100      0                      200.0      200.0    NaN   0.0   \n",
       "32767   2        0                      600.0      500.0    NaN   0.0   \n",
       "        68       0                      400.0        8.0    NaN   0.0   \n",
       "        81       0                      300.0      100.0    NaN   0.0   \n",
       "\n",
       "                                    order_count  \n",
       "time_id stock_id seconds_in_bucket               \n",
       "5       68       0                          0.0  \n",
       "        100      0                          0.0  \n",
       "        111      0                          0.0  \n",
       "11      68       0                          0.0  \n",
       "        81       0                          0.0  \n",
       "...                                         ...  \n",
       "32763   68       0                          0.0  \n",
       "        100      0                          0.0  \n",
       "32767   2        0                          0.0  \n",
       "        68       0                          0.0  \n",
       "        81       0                          0.0  \n",
       "\n",
       "[14413 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "bf = s2.groupby(['time_id','stock_id'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "    bf['price'].first()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "time_id  stock_id\n",
       "5        2           1.000688\n",
       "         68          1.000585\n",
       "         81          1.003518\n",
       "         100         1.000103\n",
       "         111         1.002161\n",
       "                       ...   \n",
       "32767    2           0.999298\n",
       "         68          1.000764\n",
       "         81          0.999430\n",
       "         100         0.999315\n",
       "         111         1.000101\n",
       "Name: price, Length: 19149, dtype: float32"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "#s2.loc[(:,:,0),'price'] = bf['price'].first()\r\n",
    "s2.loc[s2.index.get_level_values(2)==0,'price'] = bf['price'].first()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "s2.isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "bid_price1     3029793\n",
       "ask_price1     3029793\n",
       "bid_price2     3029793\n",
       "ask_price2     3029793\n",
       "bid_size1      3029793\n",
       "ask_size1      3029793\n",
       "bid_size2      3029793\n",
       "ask_size2      3029793\n",
       "price          9379063\n",
       "size                 0\n",
       "order_count          0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "#s2.loc[:,:,1:] = s2.loc[:,:,1:].fillna(method='ffill')\r\n",
    "#s2.loc[:,:,1:].fillna(method='ffill',inplace=True)\r\n",
    "s2.fillna(method='ffill',inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "s2.isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "bid_price1     0\n",
       "ask_price1     0\n",
       "bid_price2     0\n",
       "ask_price2     0\n",
       "bid_size1      0\n",
       "ask_size1      0\n",
       "bid_size2      0\n",
       "ask_size2      0\n",
       "price          0\n",
       "size           0\n",
       "order_count    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looping through each individual stocks, we can get the past realized volatility as prediction for each individual stocks."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "s2['order_count'] = s2['order_count'].astype('int16')\r\n",
    "s2[['bid_size1','ask_size1','bid_size2','ask_size2','size']] = s2[['bid_size1','ask_size1','bid_size2','ask_size2','size']].astype('int32')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "# s2['bid_size'] = (s2['bid_size1'] + s2['bid_size2'])\r\n",
    "# s2['bid_price'] = (s2['bid_price1'] * s2['bid_size1'] + s2['bid_price2'] * s2['bid_size2'])/(s2['bid_size1'] + s2['bid_size2'])\r\n",
    "\r\n",
    "# s2['ask_size'] = (s2['ask_size1'] + s2['ask_size2'])\r\n",
    "# s2['ask_price'] = (s2['ask_price1'] * s2['ask_size1'] + s2['ask_price2'] * s2['ask_size2'])/(s2['ask_size1'] + s2['ask_size2'])\r\n",
    "\r\n",
    "#s2['wap'] = (((s2['bid_price1'] * s2['bid_size1'] + s2['bid_price2'] * s2['bid_size2'])/(s2['bid_size1'] + s2['bid_size2']) * (s2['ask_size1'] + s2['ask_size2'])) + ((s2['ask_price1'] * s2['ask_size1'] + s2['ask_price2'] * s2['ask_size2'])/(s2['ask_size1'] + s2['ask_size2'])) * (s2['bid_size1'] + s2['bid_size2'])) / ((s2['bid_size1'] + s2['bid_size2']) +  (s2['ask_size1'] + s2['ask_size2']))\r\n",
    "\r\n",
    "s2['order_wap'] = (((s2['bid_price1'] * s2['bid_size1'] + s2['bid_price2'] * s2['bid_size2'])/(s2['bid_size1'] + s2['bid_size2']) * (s2['ask_size1'] + s2['ask_size2'])) + ((s2['ask_price1'] * s2['ask_size1'] + s2['ask_price2'] * s2['ask_size2'])/(s2['ask_size1'] + s2['ask_size2'])) * (s2['bid_size1'] + s2['bid_size2'])) / ((s2['bid_size1'] + s2['bid_size2']) +  (s2['ask_size1'] + s2['ask_size2']))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "s2['trade_wap'] = s2.groupby(['time_id','stock_id'])['price'].apply(lambda x: pow(x - x.mean(),2))\r\n",
    "#s2['trade_wap_sq'] = s2.groupby(['time_id','stock_id'])['price'].apply(lambda x: x - x.mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "pd.options.display.float_format = '{:,.16f}'.format"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "def trade_volatility(trade_wap_prices):\r\n",
    "    return np.sqrt(np.sum(trade_wap_prices)/len(trade_wap_prices))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "s2['log_return'] = s2.groupby(['time_id','stock_id'])['order_wap'].apply(log_return)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "s2['log_return'].isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 's2' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-64ffbe9b5bb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log_return'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 's2' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "#remove the rows with null values of log return\r\n",
    "#s2[~s2['log_return'].isnull()]['log_return']\r\n",
    "df_realized_vol_per_stock =  pd.DataFrame(s2[~s2['log_return'].isnull()]['log_return'].groupby(['time_id','stock_id']).agg(order_volatility))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "df_realized_vol_per_stock.isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "log_return    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "df_realized_vol_per_stock"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>log_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <th>stock_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th>2</th>\n",
       "      <td>0.0018733931133985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.0023004176145590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0054617860000476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0046436459937157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.0029989438960921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">32767</th>\n",
       "      <th>2</th>\n",
       "      <td>0.0010246982159702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.0013834203207654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0026151711543734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0019775423480388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.0012556054605663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19149 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         log_return\n",
       "time_id stock_id                   \n",
       "5       2        0.0018733931133985\n",
       "        68       0.0023004176145590\n",
       "        81       0.0054617860000476\n",
       "        100      0.0046436459937157\n",
       "        111      0.0029989438960921\n",
       "...                             ...\n",
       "32767   2        0.0010246982159702\n",
       "        68       0.0013834203207654\n",
       "        81       0.0026151711543734\n",
       "        100      0.0019775423480388\n",
       "        111      0.0012556054605663\n",
       "\n",
       "[19149 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "df_realized_vol_per_stock.index.get_level_values(0)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_realized_vol_per_stock' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-89662916b887>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_realized_vol_per_stock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_realized_vol_per_stock' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "#df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock.apply(lambda x: fff(x.index.get_level_values(1),x.index.get_level_values(0)), axis=1 )\r\n",
    "#df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock.apply(lambda x: x.index.get_level_values(1)+x.index.get_level_values(0))\r\n",
    "df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock.apply(lambda x: x.index.get_level_values(1).astype(str) + \"-\" + x.index.get_level_values(0).astype(str))\r\n",
    "\r\n",
    "#f'{stock_id}-{x}'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "df_realized_vol_per_stock['trade_return'] = pd.DataFrame(s2['trade_wap'].groupby(['time_id','stock_id']).agg(trade_volatility))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "df_realized_vol_per_stock"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>log_return</th>\n",
       "      <th>row_id</th>\n",
       "      <th>trade_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <th>stock_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th>2</th>\n",
       "      <td>0.0018733931133985</td>\n",
       "      <td>2-5</td>\n",
       "      <td>0.0005385612603277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.0023004176145590</td>\n",
       "      <td>68-5</td>\n",
       "      <td>0.0005042065749876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0054617860000476</td>\n",
       "      <td>81-5</td>\n",
       "      <td>0.0012333415215835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0046436459937157</td>\n",
       "      <td>100-5</td>\n",
       "      <td>0.0010931357974187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.0029989438960921</td>\n",
       "      <td>111-5</td>\n",
       "      <td>0.0005883899284527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">32767</th>\n",
       "      <th>2</th>\n",
       "      <td>0.0010246982159702</td>\n",
       "      <td>2-32767</td>\n",
       "      <td>0.0003467606729828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.0013834203207654</td>\n",
       "      <td>68-32767</td>\n",
       "      <td>0.0002697620948311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0026151711543734</td>\n",
       "      <td>81-32767</td>\n",
       "      <td>0.0005826270207763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0019775423480388</td>\n",
       "      <td>100-32767</td>\n",
       "      <td>0.0007258245022967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.0012556054605663</td>\n",
       "      <td>111-32767</td>\n",
       "      <td>0.0003218931669835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19149 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         log_return     row_id       trade_return\n",
       "time_id stock_id                                                 \n",
       "5       2        0.0018733931133985        2-5 0.0005385612603277\n",
       "        68       0.0023004176145590       68-5 0.0005042065749876\n",
       "        81       0.0054617860000476       81-5 0.0012333415215835\n",
       "        100      0.0046436459937157      100-5 0.0010931357974187\n",
       "        111      0.0029989438960921      111-5 0.0005883899284527\n",
       "...                             ...        ...                ...\n",
       "32767   2        0.0010246982159702    2-32767 0.0003467606729828\n",
       "        68       0.0013834203207654   68-32767 0.0002697620948311\n",
       "        81       0.0026151711543734   81-32767 0.0005826270207763\n",
       "        100      0.0019775423480388  100-32767 0.0007258245022967\n",
       "        111      0.0012556054605663  111-32767 0.0003218931669835\n",
       "\n",
       "[19149 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "# def past_realized_volatility_per_stock(list_file,prediction_column_name):\r\n",
    "#     df_past_realized = pd.DataFrame()\r\n",
    "#     for file in list_file:\r\n",
    "#         df_past_realized = pd.concat([df_past_realized,\r\n",
    "#                                      realized_volatility_per_time_id(file,prediction_column_name)])\r\n",
    "#     return df_past_realized\r\n",
    "# df_past_realized_train = past_realized_volatility_per_stock(list_file=list_order_book_file_train,\r\n",
    "#                                                            prediction_column_name='pred')"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's join the output dataframe with train.csv to see the performance of the naive prediction on training set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\r\n",
    "train = train[['row_id','target']]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will evaluate the naive prediction result by two metrics: RMSPE and R squared."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "df_joined = train.merge(df_realized_vol_per_stock, on = ['row_id'], how = 'inner')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "df_joined.info()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_joined' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f8062c43b58a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_joined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_joined' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "from sklearn.metrics import r2_score\r\n",
    "def rmspe(y_true, y_pred):\r\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))) * 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "R2 = round(r2_score(y_true = df_joined['target'], y_pred = df_joined['log_return']),3)\r\n",
    "RMSPE = round(rmspe(y_true = df_joined['target'], y_pred = df_joined['log_return']),3)\r\n",
    "print(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}%')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "R2 = round(r2_score(y_true = df_joined['target'], y_pred = df_joined['log_return'] + np.sqrt(df_joined['trade_return'])),3)\r\n",
    "RMSPE = round(rmspe(y_true = df_joined['target'], y_pred = df_joined['log_return'] + np.sqrt(df_joined['trade_return'])),3)\r\n",
    "print(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}%')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "jovian.commit(filename=\"my-zero-to-gbm-proj-assign.ipynb\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Machine Learning\r\n",
    "\r\n",
    "Now we will start applying ML techniques to predict the volataility of the next 10 minutes window for each time-id/stock-id based on the order book volatility and trade volatility\r\n",
    "\r\n",
    "we will learn the hyper parameters givne using the training targets for the same\r\n",
    "\r\n",
    "we will use 2 different models to do the same"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Graident Bossting\r\n",
    "\r\n",
    "We're now ready to train our gradient boosting machine (GBM) model. Here's how a GBM model works:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from xgboost import XGBRegressor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Intel Extension for Scikit-learn\r\n",
    "\r\n",
    "Intel(R) Extension for Scikit-learn* dynamically patches scikit-learn estimators to use Intel(R) oneAPI Data Analytics Library as the underlying solver, while getting the same solution faster.\r\n",
    "\r\n",
    "To install these Intel-optimized packages for scikit-learn on Windows, Mac, and Linux x86_64, simply:\r\n",
    "\r\n",
    "conda install scikit-learn-intelex\r\n",
    "\r\n",
    "Once installed, there are two ways in which you can enable the replacement patching functionality for scikit-learn. You can enable it when you run your application:\r\n",
    "\r\n",
    "python -m sklearnex my_application.py\r\n",
    "\r\n",
    "Or you can explicitly enable the patching in your code:\r\n",
    "\r\n",
    "from sklearnex import patch_sklearn\r\n",
    "\r\n",
    "patch_sklearn()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "from sklearnex import patch_sklearn\r\n",
    "patch_sklearn()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Lazy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cross Validation\r\n",
    "\r\n",
    " create a validation set before training our XGBoost model. We'll use a different validation strategy this time, called <b> ShuffleSplit </b> cross validation (source):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "from sklearn.model_selection import ShuffleSplit"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "ss = ShuffleSplit(n_splits = 5, test_size = 0.25, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's define a helper function train_and_evaluate which trains a model the given parameters and returns the trained model, training error and validation error."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_and_evaluate(X_train, train_targets, X_val, val_targets, **params):\r\n",
    "    model = XGBRegressor(random_state=42, n_jobs=-1, **params)\r\n",
    "    model.fit(X_train, train_targets)\r\n",
    "    train_R2 = round(r2_score(train_targets, model.predict(X_train)),3)\r\n",
    "    train_RMSPE = round(rmspe(train_targets, model.predict(X_train)),3)\r\n",
    "    val_R2 = round(r2_score(val_targets, model.predict(X_val)),3)\r\n",
    "    val_RMSPE = round(rmspe(val_targets, model.predict(X_val),),3)\r\n",
    "\r\n",
    "    # train_rmse = rmse(model.predict(X_train), train_targets)\r\n",
    "    # val_rmse = rmse(model.predict(X_val), val_targets)\r\n",
    "    return model, train_R2, train_RMSPE, val_R2, val_RMSPE\r\n",
    "#n_jobs = -1 means that use all the available threads in that machine where the alogorithm is running "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will train the model for each split data of the ShuffleSplit"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_joined.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "inputs = df_joined[['log_return', 'trade_return']].copy()\r\n",
    "targets = df_joined['target'].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "inputs\r\n",
    "#targets"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return</th>\n",
       "      <th>trade_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0018733931133985</td>\n",
       "      <td>0.0005385612603277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0008151048469293</td>\n",
       "      <td>0.0003309202729724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0012939132651704</td>\n",
       "      <td>0.0002343668165850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0015225304382781</td>\n",
       "      <td>0.0005046058795415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0012425119932203</td>\n",
       "      <td>0.0002491848717909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19144</th>\n",
       "      <td>0.0024886340803033</td>\n",
       "      <td>0.0005013425834477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19145</th>\n",
       "      <td>0.0009824073836777</td>\n",
       "      <td>0.0002220391470473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19146</th>\n",
       "      <td>0.0019381003855530</td>\n",
       "      <td>0.0010461938800290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19147</th>\n",
       "      <td>0.0025020021033653</td>\n",
       "      <td>0.0006868820055388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19148</th>\n",
       "      <td>0.0012556054605663</td>\n",
       "      <td>0.0003218931669835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19149 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              log_return       trade_return\n",
       "0     0.0018733931133985 0.0005385612603277\n",
       "1     0.0008151048469293 0.0003309202729724\n",
       "2     0.0012939132651704 0.0002343668165850\n",
       "3     0.0015225304382781 0.0005046058795415\n",
       "4     0.0012425119932203 0.0002491848717909\n",
       "...                  ...                ...\n",
       "19144 0.0024886340803033 0.0005013425834477\n",
       "19145 0.0009824073836777 0.0002220391470473\n",
       "19146 0.0019381003855530 0.0010461938800290\n",
       "19147 0.0025020021033653 0.0006868820055388\n",
       "19148 0.0012556054605663 0.0003218931669835\n",
       "\n",
       "[19149 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "from lazypredict.Supervised import LazyRegressor\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "models = []\r\n",
    "\r\n",
    "for train_idxs, val_idxs in ss.split(inputs):\r\n",
    "    X_train, train_targets = inputs.iloc[train_idxs], targets.iloc[train_idxs]\r\n",
    "    X_val, val_targets = inputs.iloc[val_idxs], targets.iloc[val_idxs]\r\n",
    "    model, train_R2, train_RMSPE, val_R2, val_RMSPE = train_and_evaluate(X_train, \r\n",
    "                                                     train_targets, \r\n",
    "                                                     X_val, \r\n",
    "                                                     val_targets, \r\n",
    "                                                     max_depth=5, \r\n",
    "                                                     n_estimators=50)\r\n",
    "    models.append(model)\r\n",
    "    print('Train R2: {}, Train RMSPE: {}, Validation R2: {}, Validation RMSPE: {}'.format(train_R2, train_RMSPE, val_R2, val_RMSPE))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_and_evaluate' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7500/4047393419.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     model, train_R2, train_RMSPE, val_R2, val_RMSPE = train_and_evaluate(X_train, \n\u001b[0m\u001b[0;32m      7\u001b[0m                                                      \u001b[0mtrain_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                                      \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_and_evaluate' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's also define a function to average predictions from the 5 different models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def predict_avg(models, inputs):\r\n",
    "    return np.mean([model.predict(inputs) for model in models], axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds = predict_avg(models, inputs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "# explicitly require this experimental feature\r\n",
    "from sklearn.experimental import enable_halving_search_cv\r\n",
    "# now you can import normally from model_selection\r\n",
    "from sklearn.model_selection import HalvingGridSearchCV"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'enable_halving_search_cv' from 'sklearn.experimental' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\experimental\\__init__.py)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7500/3765649220.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# explicitly require this experimental feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menable_halving_search_cv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# now you can import normally from model_selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHalvingGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'enable_halving_search_cv' from 'sklearn.experimental' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\experimental\\__init__.py)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = XGBRegressor(random_state=42, n_jobs=-1)\r\n",
    "param_grid = {\"max_depth\": [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, None]],\r\n",
    "              \"n_estimators\" : list(range(10,51,2)),\r\n",
    "              \"learning_rate\": np.logspace(-3,3,100),\r\n",
    "              # \"booster\": ['gbtree', 'gblinear','dart'],\r\n",
    "              # \"gamma\": np.logspace(-1,1,100),\r\n",
    "              \"subsample\": np.linspace(0.1,1.0,9, endpoint=False),\r\n",
    "              # \"num_parallel_tree\": range(1,6,1),\r\n",
    "              # \"reg_alpha\": np.logspace(-3,3,300),\r\n",
    "              # \"reg_lambda\": np.logspace(-3,3,300)\r\n",
    "            }\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "models = []\r\n",
    "for train_idxs, val_idxs in ss.split(inputs):\r\n",
    "    X_train, train_targets = inputs.iloc[train_idxs], targets.iloc[train_idxs]\r\n",
    "    X_val, val_targets = inputs.iloc[val_idxs], targets.iloc[val_idxs]\r\n",
    "    grid_search = HalvingGridSearchCV(model, param_grid, random_state=42).fit(X_train, train_targets)\r\n",
    "    model, train_R2, train_RMSPE, val_R2, val_RMSPE = train_and_evaluate(X_train, \r\n",
    "                                                    train_targets, \r\n",
    "                                                    X_val, \r\n",
    "                                                    val_targets, \r\n",
    "                                                    **grid_search.best_params_)\r\n",
    "    models.append(model)\r\n",
    "    print('Train R2: {}, Train RMSPE: {}, Validation R2: {}, Validation RMSPE: {}'.format(train_R2, train_RMSPE, val_R2, val_RMSPE))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "models = []\r\n",
    "for train_idxs, val_idxs in ss.split(inputs):\r\n",
    "    X_train, train_targets = inputs.iloc[train_idxs], targets.iloc[train_idxs]\r\n",
    "    X_val, val_targets = inputs.iloc[val_idxs], targets.iloc[val_idxs]\r\n",
    "    X_train = np.ascontiguousarray(X_train).reshape(-1,2)\r\n",
    "    train_targets = np.ascontiguousarray(train_targets).reshape(-1,1)\r\n",
    "    X_val = np.ascontiguousarray(X_val).reshape(-1,2)\r\n",
    "    val_targets = np.ascontiguousarray(val_targets).reshape(-1,1)\r\n",
    "    reg = LazyRegressor(ignore_warnings=False, random_state=11111, verbose=True)\r\n",
    "    models, predictions = reg.fit(X_train, X_val, train_targets, val_targets)  # pass all sets\r\n",
    "    print(models.head(100))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fit LazyRegressor\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid_search.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Discussion on cross validation designs\r\n",
    "\r\n",
    "https://www.kaggle.com/vishnurapps/undersanding-kfold-stratifiedkfold-and-groupkfold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}